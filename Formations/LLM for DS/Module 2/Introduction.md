1. Overview and Objectives
Goal: By the end of this module, learners should be able to:

Understand the core components of the Transformer model.
Differentiate between encoder-only, decoder-only, and encoder-decoder Transformer architectures.
Implement a minimal Transformer (or components of it) in code (PyTorch/TensorFlow).
Comprehend how attention mechanisms (particularly self-attention) power large language models.
2. Reading and Video References
Mandatory Reading:

Attention Is All You Need (Vaswani et al., 2017)
Focus on Sections 2 & 3 (Scaled Dot-Product Attention, Multi-Head Attention, Positional Encoding).
The Illustrated Transformer by Jay Alammar
Great visual introduction to each component.
Video Lectures/Playlists:

Stanford CS224N 2021 – Lecture on Transformers
Approx. 1-hour deep dive into attention and Transformers.
Hugging Face Course – Chapter on Transformers
Short, practical video explanations plus notebooks.
(In your course platform, embed or link these resources directly for easy reference.)

